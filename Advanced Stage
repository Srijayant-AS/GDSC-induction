import torch

def get_rays(H, W, focal, c2w):
    """
    Computes rays passing through each pixel (H, W).
    - focal: Focal length of the camera.
    - c2w: Camera-to-world transformation matrix (4x4).
    """
    
    i, j = torch.meshgrid(torch.linspace(0, W-1, W), torch.linspace(0, H-1, H), indexing='xy')
    
    
    dirs = torch.stack([(i - W * 0.5) / focal, 
                        -(j - H * 0.5) / focal, 
                        -torch.ones_like(i)], -1)
    
    
    rays_d = torch.sum(dirs[..., None, :] * c2w[:3, :3], -1) 
    
    
    rays_o = c2w[:3, -1].expand(rays_d.shape)
    
    return rays_o, rays_d

def sample_along_rays(rays_o, rays_d, near, far, n_samples):
    """
    Generates 3D points by sampling along rays between 'near' and 'far' bounds.
    """
    t_vals = torch.linspace(0., 1., steps=n_samples)
    z_vals = near * (1. - t_vals) + far * t_vals
    
    
    mids = .5 * (z_vals[..., 1:] + z_vals[..., :-1])
    upper = torch.cat([mids, z_vals[..., -1:]], -1)
    lower = torch.cat([z_vals[..., :1], mids], -1)
    t_rand = torch.rand(z_vals.shape)
    z_vals = lower + (upper - lower) * t_rand

    
    pts = rays_o[..., None, :] + rays_d[..., None, :] * z_vals[..., :, None]
    return pts, z_vals

import torch.nn as nn
import torch.nn.functional as F

class NeRF(nn.Module):
    def __init__(self, D=8, W=256):
        super(NeRF, self).__init__()
        # 8-layer MLP for density (sigma) and a feature vector
        self.pts_linears = nn.ModuleList([nn.Linear(3, W)] + 
                                         [nn.Linear(W, W) for _ in range(D-1)])
        
        
        self.views_linears = nn.ModuleList([nn.Linear(W + 3, W//2)])
        self.feature_linear = nn.Linear(W, W)
        self.alpha_linear = nn.Linear(W, 1)
        self.rgb_linear = nn.Linear(W//2, 3)

    def forward(self, x, viewdirs):
        
        h = x
        for i, l in enumerate(self.pts_linears):
            h = F.relu(l(h))
        
        
        alpha = self.alpha_linear(h)
        
        
        feature = self.feature_linear(h)
        h = torch.cat([feature, viewdirs], -1)
        
        for l in self.views_linears:
            h = F.relu(l(h))
            
        rgb = torch.sigmoid(self.rgb_linear(h))
        return rgb, alpha

def volume_rendering(rgb, sigma, z_vals, rays_d):
    """
    Accumulates colors and densities along rays using numerical integration.
    """
    
    dists = z_vals[..., 1:] - z_vals[..., :-1]
    dists = torch.cat([dists, torch.Tensor([1e10]).expand(dists[..., :1].shape)], -1)
    dists = dists * torch.norm(rays_d[..., None, :], dim=-1)

    
    alpha = 1. - torch.exp(-F.relu(sigma) * dists)
    
    
    weights = alpha * torch.cumprod(torch.cat([torch.ones((alpha.shape[0], 1)), 1.-alpha + 1e-10], -1), -1)[:, :-1]
    
    
    rgb_map = torch.sum(weights[..., None] * rgb, -2)
    return rgb_map

